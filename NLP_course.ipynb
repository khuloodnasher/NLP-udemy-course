{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP course.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2n0BgPk9WuqH/D0Az/0E0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khuloodnasher/NLP-udemy-course/blob/main/NLP_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fl-LAmPI9pi"
      },
      "source": [
        "person='Khulood'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFjvO9-cQJrb",
        "outputId": "8298ce15-431c-4cb9-b356-5b00bd5f4930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# old python\n",
        "print ('my name is {}'.format(person))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my name is Khulood\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA05NBDsQbJs",
        "outputId": "68b70015-51d7-4c5f-d582-d2bdc04b368f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'my name is {person}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my name is Khulood\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nohOVNhSTWYS",
        "outputId": "31592fe5-f4ca-4f99-84e5-8261e41bc111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'{person}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Khulood\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msQQzpkdUIQG"
      },
      "source": [
        "d={'a':123,'b':456}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5RTE18CUlie",
        "outputId": "8188f961-5ae6-4f95-d0fd-a1c15e317b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"my number is {d ['b']}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my number is 456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpOIDSMXUrlL"
      },
      "source": [
        "mylist=[0,1,2]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8jjinNfV-O3",
        "outputId": "1e7314c0-b3b5-47ed-ae59-c4c12ddf0bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"my number is {mylist[1]}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my number is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56ioQ6M1WIco"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuDlBDfZhav7"
      },
      "source": [
        "how to represent word to feed to neural net work\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-S52YKMhttS"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksFSBFFgh88I",
        "outputId": "70839d4e-736d-4329-afdc-7efe4a246470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# put our words in a list\n",
        "sentences=['I love my dog','I love my cat','You look cool']\n",
        "\n",
        "mysentence=Tokenizer(num_words=100) # just in case I want to add more words later\n",
        "#fitting the texts\n",
        "mysentence.fit_on_texts(sentences)# this line is taking each word from the sentences and give it a specific number\n",
        "indixingwords=mysentence.word_index\n",
        "print(indixingwords)\n",
        "# one good thing about tokinizer it returns everything lower case as in I and other letters\n",
        "# as we noticed each word got a unique number\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5, 'you': 6, 'look': 7, 'cool': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJb8cypZkiTN",
        "outputId": "8610e1ab-d196-4439-daf4-d991f519f4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now how to represent sentences using squence\n",
        "sentences=['I love my dog','I love my cat','You look cool']\n",
        "\n",
        "\n",
        "\n",
        "sequences1=mysentence.texts_to_sequences(sentences)\n",
        "print(sequences1)\n",
        "\n",
        "# sequences give numeric value to the tokinized words but the spliting the sentences into lists"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 3, 4], [1, 2, 3, 5], [6, 7, 8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1F_BnvrBels",
        "outputId": "dad3cc57-b9bb-45ab-e4cd-8031b59ac615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now we will test our tokenized text\n",
        "test_data=[\n",
        "    'you are amazing',\n",
        "    'loves my cat'\n",
        "]\n",
        "\n",
        "sequences2=mysentence.texts_to_sequences(test_data)\n",
        "print(sequences2)\n",
        "# As we noticed that the  word 'you' in training data and has number 6,but 'are' and 'amazing' were not recognized\n",
        "# word 'my' has numeric 3 and cat has numeric value 5"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6], [3, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO3OnrUVDqGN"
      },
      "source": [
        "# to avoid any missing meaning in the sentence I can give all the missing words a number, this number is unique but for the words that are not in training data set\n",
        "\n",
        "\n",
        "mynewsentence=Tokenizer(num_words=100,oov_token=\"<oov>\")# when we give numbers for each word, we will give the unknown words in training a specific number\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERY6hPxDH3mx",
        "outputId": "aefaa9b8-a8eb-47e7-ff30-0d7981f6070d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now lets run our test again\n",
        "test_data=[\n",
        "    'you are amazing',\n",
        "    'loves my cat'\n",
        "]\n",
        "\n",
        "sequences3=mynewsentence.texts_to_sequences(test_data)\n",
        "print(sequences3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[None, None, None], [None, None, None]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuP6uOc9ICUE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}